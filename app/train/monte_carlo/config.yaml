# === Exact paths for MacOS setup ===
data_path: "/Users/omeremeksiz/Desktop/reinforcement-learning/data/data_v3/10KQuantize.xlsx"

# === Output files ===
output_paths:
  # Text outputs
  tolerance_pairs_path: "output/tolerance_pairs.txt"
  final_arr_path: "output/final_arr.txt"
  qvalue_update_path: "output/qvalue_update.txt"
  mc_qvalue_path: "output/mc_qvalue_output.txt"
  best_actions_mc_path: "output/best_actions.txt"
  qvalue_updates_path: "output/qvalue_updates.xlsx"
  target_state_path: "output/target_state.txt"
  cluster_histogram_path: "cluster_histogram.png"
  qvalue_sate_plot_path: "qvalue_vs_state.png"
  switching_point_trajectory_path: "switching_point_trajectory"

  # HTML outputs
  mc_qvalue_html_path: "html/mc_qvalue.html"
  mc_best_actions_html_path: "html/mc_best_actions.html"
  html_control: false # true/false

# === Training parameters ===
training:
  seed: 42
  initial_q_value: -125.0
  learning_rate: 0.01
  gamma: 0.99
  exploration_probability: 0.5
  min_weight: 74
  max_weight: 76
  overflow_penalty: -50
  underflow_penalty: -35

# === Target state config ===
target_state:
  weight: 51
  action: 1
